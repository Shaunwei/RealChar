# ---------------- Language Model Configuration ----------------
# Option 1: ReByte Agents (Recommended)
# Obtain your ReByte API key at https://rebyte.ai > Settings > API Keys
REBYTE_API_KEY=YOUR_API_KEY

# Option 2: Alternate LLM APIs
# Uncomment and configure the desired API
# Supported APIs: OpenAI, Anthropic, Anyscale, Local LLM with Openai Compatiable API
# OpenAI: "gpt-4", "gpt-3.5-turbo-16k", etc.
# Anthropic: "claude-instant-1", "claude-2", etc.
# Anyscale: "meta-llama/Llama-2-70b-chat-hf", etc.
# Local LLM: "localhost"
# LLM_MODEL_USE=gpt-3.5-turbo-16k

# API Keys
# OPENAI_API_KEY=YOUR_API_KEY
# ANTHROPIC_API_KEY=YOUR_API_KEY
# ANYSCALE_ENDPOINT_API_KEY=YOUR_API_KEY

# Local LLM Configuration (with Openai Compatiable API)
# Example URL: "http://localhost:8001/v1"
# LOCAL_LLM_URL=

# Option 3: Azure OpenAI API
# For Azure OpenAI, uncomment and set the following entries
# OPENAI_API_TYPE=azure
# OPENAI_API_VERSION=2023-03-15-preview
# Base URL found in the Azure portal under your Azure OpenAI resource
# OPENAI_API_BASE=https://your-base-url.openai.azure.com
# OPENAI_API_MODEL_DEPLOYMENT_NAME=gpt-35-turbo
# OPENAI_API_EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002

# ---------------- Speech to Text Configuration ----------------
# Choose engine: LOCAL_WHISPER, LOCAL_WHISPER_X (recommended), WHISPER_X_API, OPENAI_WHISPER, GOOGLE
SPEECH_TO_TEXT_USE=LOCAL_WHISPER_X

# Local Whisper Configuration
# Choose model: "tiny", "base", "small", "medium", "large"
LOCAL_WHISPER_MODEL=base
# Journal Mode (Optional)
# Obtain HuggingFace ACCESS TOKEN at https://huggingface.co/settings/tokens
# Grant access to models at https://github.com/m-bain/whisperX?tab=readme-ov-file#speaker-diarization
# HUGGING_FACE_ACCESS_TOKEN=YOUR_API_KEY

# Whisper X API Configuration
# WHISPER_X_API_URL=
# WHISPER_X_API_URL_JOURNAL=
# WHISPER_X_API_KEY=YOUR_API_KEY

# OpenAI Whisper API Configuration
# OPENAI_WHISPER_API_KEY=YOUR_API_KEY

# Google Speech to Text API Configuration
# GOOGLE_APPLICATION_CREDENTIALS=google_credentials.json

# ---------------- Text to Speech Configuration ----------------
# Choose TTS engine: EDGE_TTS (free), ELEVEN_LABS, GOOGLE_TTS, XTTS
TEXT_TO_SPEECH_USE=EDGE_TTS

# Eleven Labs Configuration
# ELEVEN_LABS_API_KEY=YOUR_API_KEY
# Set to "true" for V2 model access
# ELEVEN_LABS_USE_V2=

# XTTS Configuration
# XTTS_API_KEY=YOUR_API_KEY
# XTTS_API_URL=

# ---------------- Database Configuration ----------------
# SQLite Database URL (to initialize database see README)
# Format: sqlite:///<path_to_db_file>
DATABASE_URL=sqlite:///./test.db

# ---------------- Optional Configuration ----------------
# User Authentication
# Enable login by setting to "true", leave empty to disable
# USE_AUTH=
# Firebase Configuration
# Obtain Firebase credentials from https://console.firebase.google.com
# FIREBASE_CONFIG_PATH=firebase_credentials.json

# Google Cloud Storage Bucket Name
GCP_STORAGE_BUCKET_NAME=assistly

# LLM Tracing
# LANGCHAIN_TRACING_V2=false # Default: off
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
# LANGCHAIN_API_KEY=YOUR_LANGCHAIN_API_KEY
# LANGCHAIN_PROJECT=YOUR_LANGCHAIN_PROJECT

# Knowledge Base (Character Catalog)
# Set to "false" to skip updating the knowledge base on startup, else forced update
# OVERWRITE_CHROMA=false

# Twilio Integration
# Obtain Account SID and Auth Token from https://console.twilio.com
# Use a number you own for outgoing calls
# TWILIO_ACCOUNT_SID=
# TWILIO_ACCESS_TOKEN=
# DEFAULT_CALLOUT_NUMBER=
