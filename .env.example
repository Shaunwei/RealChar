# ----------------------- Language Model Configurations -----------------------
# Option 1: ReByte Agents (Recommended)
# Obtain your ReByte API key at https://rebyte.ai > Settings > API Keys
REBYTE_API_KEY=YOUR_API_KEY

# Option 2: Alternate LLM APIs
# Uncomment and configure the desired API
# Supported APIs: OpenAI, Anthropic, Anyscale, Local LLM with Openai Compatiable API
# OpenAI: "gpt-4", "gpt-3.5-turbo-16k", etc.
# Anthropic: "claude-instant-1", "claude-2", etc.
# Anyscale: "meta-llama/Llama-2-70b-chat-hf", etc.
# Local LLM: "localhost"
# LLM_MODEL_USE=gpt-3.5-turbo-16k

# API Keys
# Note that if not using ReByte, OPENAI_API_KEY is required for generating embeddings for
# the knowledge base, no matter what LLM API is being used
# OPENAI_API_KEY=YOUR_API_KEY
# ANTHROPIC_API_KEY=YOUR_API_KEY
# ANYSCALE_ENDPOINT_API_KEY=YOUR_API_KEY

# Local LLM Configuration (with Openai Compatiable API)
# Example URL: "http://localhost:8001/v1"
# LOCAL_LLM_URL=

# Option 3: Azure OpenAI API
# For Azure OpenAI, uncomment and set the following entries
# OPENAI_API_TYPE=azure
# OPENAI_API_VERSION=2023-03-15-preview
# Base URL found in the Azure portal under your Azure OpenAI resource
# OPENAI_API_BASE=https://your-base-url.openai.azure.com
# OPENAI_API_MODEL_DEPLOYMENT_NAME=gpt-35-turbo
# OPENAI_API_EMBEDDING_DEPLOYMENT_NAME=text-embedding-ada-002

# ----------------------- Speech to Text Configurations -----------------------
# Choose engine: LOCAL_WHISPER, LOCAL_WHISPER_X (recommended), WHISPER_X_API, OPENAI_WHISPER, GOOGLE
SPEECH_TO_TEXT_USE=LOCAL_WHISPER_X

# Local Whisper Configuration
# Choose model: "tiny", "base" (recommended), "small", "medium", "large"
LOCAL_WHISPER_MODEL=base
# Uncomment if OpenCC is installed. Set to s2t for traditional Chinese, t2s for simplified Chinese
# OPENCC=
# Journal Mode (Optional)
# Journal mode is resource intensive, only enable if you have GPU and plenty of RAM
# JOURNAL_MODE=false
# Obtain HuggingFace ACCESS TOKEN at https://huggingface.co/settings/tokens
# Grant access to required models. See https://github.com/m-bain/whisperX?tab=readme-ov-file#speaker-diarization
# HF_ACCESS_TOKEN=YOUR_API_KEY

# Whisper X API Configuration
# WHISPER_X_API_URL=
# WHISPER_X_API_URL_JOURNAL=
# WHISPER_X_API_KEY=YOUR_API_KEY

# OpenAI Whisper API Configuration
# OPENAI_WHISPER_API_KEY=YOUR_API_KEY

# Google Speech to Text API Configuration
# GOOGLE_APPLICATION_CREDENTIALS=google_credentials.json

# ----------------------- Text to Speech Configurations -----------------------
# Edge TTS Configuration
EDGE_TTS_DEFAULT_VOICE=en-US-ChristopherNeural

# Eleven Labs Configuration
# ELEVEN_LABS_API_KEY=YOUR_API_KEY
# Set to "true" for V2 model access
# ELEVEN_LABS_USE_V2=true

# Google Text to Speech API Configuration
# GOOGLE_APPLICATION_CREDENTIALS=google_credentials.json

# XTTS Configuration
# XTTS_API_KEY=YOUR_API_KEY
# XTTS_API_URL=

# -------------------------- Database Configurations --------------------------
# SQLite Database URL (to initialize database see README)
# Format: sqlite:///<path_to_db_file>
DATABASE_URL=sqlite:///./test.db

# -------------------------- Optional Configurations --------------------------
# Firebase Configuration
# Enable user login by setting USE_AUTH to "true", leave empty to disable
# Obtain Firebase credentials from https://console.firebase.google.com
# USE_AUTH=true
# FIREBASE_CONFIG_PATH=firebase_credentials.json

# Google Cloud Storage
# Use default for RealChar provided characters
# Use your own bucket to enable uploading avatars, audios and knowledges for your own characters
# You'll need to create a bucket in Google Cloud Storage and login to gcloud CLI locally
GCP_STORAGE_URL=https://storage.googleapis.com/assistly
GCP_STORAGE_BUCKET_NAME=assistly

# LLM Tracing
# LANGCHAIN_TRACING_V2=false # Default: off
# LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
# LANGCHAIN_API_KEY=YOUR_LANGCHAIN_API_KEY
# LANGCHAIN_PROJECT=YOUR_LANGCHAIN_PROJECT

# Knowledge Base (Character Catalog)
# Set to "false" to skip updating the knowledge base on startup, else force update. Default: true
# OVERWRITE_CHROMA=false

# Twilio Integration
# Obtain Account SID and Auth Token from https://console.twilio.com
# Use a number you own for outgoing calls
# TWILIO_ACCOUNT_SID=
# TWILIO_ACCESS_TOKEN=
# DEFAULT_CALLOUT_NUMBER=
